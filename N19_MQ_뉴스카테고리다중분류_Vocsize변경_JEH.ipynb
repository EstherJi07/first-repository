{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5bd0c2b-2cd1-42a4-9f05-42ed160bb4ee",
   "metadata": {},
   "source": [
    "# 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679de303-8d7d-4630-af28-0723bf6d8177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 15:38:35.376205: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-31 15:38:35.453980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735627115.491765   24379 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735627115.507215   24379 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-31 15:38:35.588111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "3.9.2\n",
      "0.13.2\n",
      "1.26.4\n",
      "2.2.3\n",
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import matplotlib\n",
    "import seaborn \n",
    "import numpy \n",
    "import pandas\n",
    "import sklearn\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(seaborn.__version__)\n",
    "print(numpy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67166373-a307-439f-8c49-3ae29723fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5579f0-fbb1-4238-bd77-aee37a4e4ea5",
   "metadata": {},
   "source": [
    "# 로이터 뉴스 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af96f54b-8d6f-40c7-ad4f-ba1811291213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e80b5a-279e-4eef-9d73-d51ae279c41a",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f11126c-51b1-4aa0-9bb3-30495b26657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(num_words):\n",
    "    # 데이터 로드\n",
    "    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, test_split=0.2)\n",
    "\n",
    "    # 단어장 생성 및 단어 인덱스 생성\n",
    "    word_index = reuters.get_word_index()\n",
    "    index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "    for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "        index_to_word[index]=token\n",
    "\n",
    "    # 디코딩 (텍스트로 변환) - train\n",
    "    decoded_train = []\n",
    "    for seq in x_train:\n",
    "        t = ' '.join([index_to_word[index] for index in seq]) # index는 seq의 각 요소(정수 인덱스), index_to_word 정수 인덱스와 단어를 매핑한 딕셔너리\n",
    "        decoded_train.append(t)\n",
    "    x_train = decoded_train\n",
    "\n",
    "    # 디코딩 (텍스트로 변환) - test (리스트로 한 번 나타내보기)\n",
    "    decoded_test = [' '.join([index_to_word[index] for index in seq]) for seq in x_test]\n",
    "    x_test = decoded_test\n",
    "    \n",
    "    # DTM 생성\n",
    "    vectorizer = CountVectorizer()\n",
    "    x_train_dtm = vectorizer.fit_transform(x_train)\n",
    "    x_test_dtm = vectorizer.transform(x_test)\n",
    "\n",
    "    # TF-IDF 변환\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "    x_test_tfidf = tfidf_transformer.transform(x_test_dtm)\n",
    "\n",
    "    return x_train_tfidf, x_test_tfidf, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5c4e7-a6ec-4974-a377-49be722bb5a6",
   "metadata": {},
   "source": [
    "## 모델 및 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87904be7-9ad6-46cb-9821-7a66a1936904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(x_train_tfidf, x_test_tfidf, y_train, y_test):\n",
    "    \n",
    "    models = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"ComplementNB\": ComplementNB(),\n",
    "        \"LogisticRegression\": LogisticRegression(C=10000, penalty='l2', max_iter=3000),\n",
    "        \"LinearSVC\": LinearSVC(C=1000, penalty='l2', max_iter=3000),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(max_depth=10, random_state=0),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=5, random_state=0),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(random_state=0),\n",
    "        \"VotingClassifier\": VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"lr\", LogisticRegression(penalty='l2', random_state=0)),\n",
    "                (\"cnb\", ComplementNB()),\n",
    "                (\"gbc\", GradientBoostingClassifier(random_state=0))\n",
    "            ],\n",
    "            voting='soft'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(x_train_tfidf, y_train)\n",
    "        predicted = model.predict(x_test_tfidf)\n",
    "        accuracy = accuracy_score(y_test, predicted)\n",
    "        f1 = f1_score(y_test, predicted, average='weighted')\n",
    "        # conf_matrix = confusion_matrix(y_test, predicted)\n",
    "        # class_report = classification_report(y_test, predicted,zero_division=0)\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1 Score\": f1,\n",
    "            # \"Confusion Matrix\": conf_matrix,\n",
    "            # \"Classification Report\": class_report\n",
    "        })\n",
    "        \n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        # print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "        # print(f\"Classification Report:\\n{class_report}\\n\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d53dec-71e6-4f1a-9416-656ec85434a0",
   "metadata": {},
   "source": [
    "- 보기 쉽게 다시 모델 및 평가 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9d13c5-8d89-4933-b673-9197caff6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(x_train_tfidf, x_test_tfidf, y_train, y_test):\n",
    "    \n",
    "    models = {\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"ComplementNB\": ComplementNB(),\n",
    "        \"LogisticRegression\": LogisticRegression(C=10000, penalty='l2', max_iter=3000),\n",
    "        \"LinearSVC\": LinearSVC(C=1000, penalty='l2', max_iter=3000),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(max_depth=10, random_state=0),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=5, random_state=0),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(random_state=0),\n",
    "        \"VotingClassifier\": VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"lr\", LogisticRegression(penalty='l2', random_state=0)),\n",
    "                (\"cnb\", ComplementNB()),\n",
    "                (\"gbc\", GradientBoostingClassifier(random_state=0))\n",
    "            ],\n",
    "            voting='soft'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(x_train_tfidf, y_train)\n",
    "        predicted = model.predict(x_test_tfidf)\n",
    "        accuracy = accuracy_score(y_test, predicted)\n",
    "        f1 = f1_score(y_test, predicted, average='weighted')\n",
    "        # conf_matrix = confusion_matrix(y_test, predicted)\n",
    "        # class_report = classification_report(y_test, predicted,zero_division=0)\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1 Score\": f1,\n",
    "            # \"Confusion Matrix\": conf_matrix,\n",
    "            # \"Classification Report\": class_report\n",
    "        })\n",
    "        \n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        # print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "        # print(f\"Classification Report:\\n{class_report}\\n\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715823dc-1f0f-4082-bffb-f0c2515ade41",
   "metadata": {},
   "source": [
    "## (1) 모든 단어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d77169-67a4-49c8-a910-40376aace8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # None\n",
    "\n",
    "# x_train_tfidf, x_test_tfidf, y_train, y_test = data_preprocessing(num_words=None)\n",
    "# results = train_and_evaluate_models(x_train_tfidf, x_test_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe25ac3-6fa6-4bb8-a2a1-2cbcc36b8761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB\n",
      "Accuracy: 0.5997\n",
      "F1 Score: 0.5046\n",
      "Model: ComplementNB\n",
      "Accuracy: 0.7649\n",
      "F1 Score: 0.7347\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.8112\n",
      "F1 Score: 0.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estherj/myenv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearSVC\n",
      "Accuracy: 0.8028\n",
      "F1 Score: 0.7990\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.6211\n",
      "F1 Score: 0.5769\n",
      "Model: RandomForest\n",
      "Accuracy: 0.6545\n",
      "F1 Score: 0.6226\n",
      "Model: GradientBoosting\n",
      "Accuracy: 0.7680\n",
      "F1 Score: 0.7627\n",
      "Model: VotingClassifier\n",
      "Accuracy: 0.7996\n",
      "F1 Score: 0.7943\n"
     ]
    }
   ],
   "source": [
    "# None\n",
    "\n",
    "x_train_tfidf, x_test_tfidf, y_train, y_test = data_preprocessing(num_words=None)\n",
    "results_none = train_and_evaluate_models(x_train_tfidf, x_test_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a9bb9-2295-4eca-b0eb-5849648de632",
   "metadata": {},
   "source": [
    "## (2) 5000개 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57740382-c30a-4ec3-b541-001fc018e8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB\n",
      "Accuracy: 0.6732\n",
      "F1 Score: 0.6013\n",
      "Model: ComplementNB\n",
      "Accuracy: 0.7707\n",
      "F1 Score: 0.7459\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.8059\n",
      "F1 Score: 0.8000\n",
      "Model: LinearSVC\n",
      "Accuracy: 0.7930\n",
      "F1 Score: 0.7891\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.6180\n",
      "F1 Score: 0.5730\n",
      "Model: RandomForest\n",
      "Accuracy: 0.7012\n",
      "F1 Score: 0.6770\n",
      "Model: GradientBoosting\n",
      "Accuracy: 0.7667\n",
      "F1 Score: 0.7650\n",
      "Model: VotingClassifier\n",
      "Accuracy: 0.7952\n",
      "F1 Score: 0.7921\n"
     ]
    }
   ],
   "source": [
    "# 5000개\n",
    "\n",
    "x_train_tfidf, x_test_tfidf, y_train, y_test = data_preprocessing(num_words=5000)\n",
    "results_5000 = train_and_evaluate_models(x_train_tfidf, x_test_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f112fb-45db-4b1c-8338-9b2142bd0025",
   "metadata": {},
   "source": [
    "## (3) 10000개 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d47f0d12-b10e-4305-9557-c19ddb8082ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB\n",
      "Accuracy: 0.6567\n",
      "F1 Score: 0.5764\n",
      "Model: ComplementNB\n",
      "Accuracy: 0.7707\n",
      "F1 Score: 0.7457\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.8085\n",
      "F1 Score: 0.8023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estherj/myenv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearSVC\n",
      "Accuracy: 0.7921\n",
      "F1 Score: 0.7878\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.6202\n",
      "F1 Score: 0.5776\n",
      "Model: RandomForest\n",
      "Accuracy: 0.6741\n",
      "F1 Score: 0.6429\n",
      "Model: GradientBoosting\n",
      "Accuracy: 0.7685\n",
      "F1 Score: 0.7648\n",
      "Model: VotingClassifier\n",
      "Accuracy: 0.7970\n",
      "F1 Score: 0.7924\n"
     ]
    }
   ],
   "source": [
    "# 10000개\n",
    "\n",
    "x_train_tfidf, x_test_tfidf, y_train, y_test = data_preprocessing(num_words=10000)\n",
    "results_10000 = train_and_evaluate_models(x_train_tfidf, x_test_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388ebec-7477-4642-920e-41e1729daecc",
   "metadata": {},
   "source": [
    "- results를 합치려고 했는데 계속 에러발생\n",
    "- def에서 return을 작성하지 않아 계속 발생한 것으로 확인됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0b3388d-f726-4c1f-b7c6-8c96b2173685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(results)  # 함수 반환값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "807d48d7-0b09-43ad-accf-4ef94ab74804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results_none))\n",
    "print(type(results_10000))\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e2d42b-5a5e-4dde-b241-3690cc3fd2e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 결과 1차 분석\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results_analysis \u001b[38;5;241m=\u001b[39m \u001b[43mresults_none\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresults_10000\u001b[49m \u001b[38;5;241m+\u001b[39m results \u001b[38;5;66;03m# results = results_5000\u001b[39;00m\n\u001b[1;32m      3\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results_analysis)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# 결과 1차 분석\n",
    "results_analysis = results_none + results_10000 + results # results = results_5000\n",
    "results_df = pd.DataFrame(results_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfb9be8-8393-4911-8b58-63aba7e65ca5",
   "metadata": {},
   "source": [
    "## (4) 3000개 \n",
    "- Logistic regression 에서 5000과 10000이 성능 향상이 크지 않아서 조금 더 작은 값에서 경향을 한 번 더 진행해보고자 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0f406eb-b167-48d5-b072-adea0dc815bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB\n",
      "Accuracy: 0.6647\n",
      "F1 Score: 0.5868\n",
      "Model: ComplementNB\n",
      "Accuracy: 0.7685\n",
      "F1 Score: 0.7440\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.8072\n",
      "F1 Score: 0.8008\n",
      "Model: LinearSVC\n",
      "Accuracy: 0.8001\n",
      "F1 Score: 0.7965\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.6207\n",
      "F1 Score: 0.5762\n",
      "Model: RandomForest\n",
      "Accuracy: 0.6736\n",
      "F1 Score: 0.6450\n",
      "Model: GradientBoosting\n",
      "Accuracy: 0.7636\n",
      "F1 Score: 0.7615\n",
      "Model: VotingClassifier\n",
      "Accuracy: 0.7943\n",
      "F1 Score: 0.7903\n"
     ]
    }
   ],
   "source": [
    "# 3000개\n",
    "\n",
    "x_train_tfidf, x_test_tfidf, y_train, y_test = data_preprocessing(num_words=3000)\n",
    "results_3000 = train_and_evaluate_models(x_train_tfidf, x_test_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85399dcb-9104-47c2-9a6e-edba7a013887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 2차 분석\n",
    "results_analysis = results_none + results_3000 + results_5000  + results_10000\n",
    "results_df = pd.DataFrame(results_analysis)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d883c0-5ffd-4ab4-ac85-f6f35a08e1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.599733</td>\n",
       "      <td>0.504567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.764915</td>\n",
       "      <td>0.734653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.811220</td>\n",
       "      <td>0.805548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.802760</td>\n",
       "      <td>0.799022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.621104</td>\n",
       "      <td>0.576928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.654497</td>\n",
       "      <td>0.622591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.768032</td>\n",
       "      <td>0.762704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>0.799644</td>\n",
       "      <td>0.794290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.673197</td>\n",
       "      <td>0.601250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.770703</td>\n",
       "      <td>0.745899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.805877</td>\n",
       "      <td>0.799952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.792965</td>\n",
       "      <td>0.789132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.617988</td>\n",
       "      <td>0.572997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.701247</td>\n",
       "      <td>0.677022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.766696</td>\n",
       "      <td>0.764988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>0.795191</td>\n",
       "      <td>0.792138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.664737</td>\n",
       "      <td>0.586803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.744042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.807213</td>\n",
       "      <td>0.800789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.800089</td>\n",
       "      <td>0.796530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.620659</td>\n",
       "      <td>0.576207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.673642</td>\n",
       "      <td>0.644993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.763580</td>\n",
       "      <td>0.761522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>0.794301</td>\n",
       "      <td>0.790293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.656723</td>\n",
       "      <td>0.576447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.770703</td>\n",
       "      <td>0.745668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.808549</td>\n",
       "      <td>0.802277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.792075</td>\n",
       "      <td>0.787799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.620214</td>\n",
       "      <td>0.577640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.674087</td>\n",
       "      <td>0.642948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.764841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>0.796972</td>\n",
       "      <td>0.792352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  F1 Score\n",
       "0        MultinomialNB  0.599733  0.504567\n",
       "1         ComplementNB  0.764915  0.734653\n",
       "2   LogisticRegression  0.811220  0.805548\n",
       "3            LinearSVC  0.802760  0.799022\n",
       "4         DecisionTree  0.621104  0.576928\n",
       "5         RandomForest  0.654497  0.622591\n",
       "6     GradientBoosting  0.768032  0.762704\n",
       "7     VotingClassifier  0.799644  0.794290\n",
       "8        MultinomialNB  0.673197  0.601250\n",
       "9         ComplementNB  0.770703  0.745899\n",
       "10  LogisticRegression  0.805877  0.799952\n",
       "11           LinearSVC  0.792965  0.789132\n",
       "12        DecisionTree  0.617988  0.572997\n",
       "13        RandomForest  0.701247  0.677022\n",
       "14    GradientBoosting  0.766696  0.764988\n",
       "15    VotingClassifier  0.795191  0.792138\n",
       "16       MultinomialNB  0.664737  0.586803\n",
       "17        ComplementNB  0.768477  0.744042\n",
       "18  LogisticRegression  0.807213  0.800789\n",
       "19           LinearSVC  0.800089  0.796530\n",
       "20        DecisionTree  0.620659  0.576207\n",
       "21        RandomForest  0.673642  0.644993\n",
       "22    GradientBoosting  0.763580  0.761522\n",
       "23    VotingClassifier  0.794301  0.790293\n",
       "24       MultinomialNB  0.656723  0.576447\n",
       "25        ComplementNB  0.770703  0.745668\n",
       "26  LogisticRegression  0.808549  0.802277\n",
       "27           LinearSVC  0.792075  0.787799\n",
       "28        DecisionTree  0.620214  0.577640\n",
       "29        RandomForest  0.674087  0.642948\n",
       "30    GradientBoosting  0.768477  0.764841\n",
       "31    VotingClassifier  0.796972  0.792352"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d2775-79b8-4632-bec2-3cf39c773f42",
   "metadata": {},
   "source": [
    "## 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b021d36-2806-4a02-b0d8-d7aa6f002c99",
   "metadata": {},
   "source": [
    "### 1) Accuracy 가장 높은 모델\n",
    "- Logistic regression\n",
    "  - Vocabulary Size: 3000 - Logistic Regression: 0.8008\n",
    "  - Vocabulary Size: 5000 - Logistic Regression: 0.8059\n",
    "  - Vocabulary Size: 10000 - Logistic Regression: 0.8085\n",
    "  - Vocabulary Size: None - Logistic Regression: 0.8112\n",
    "\n",
    "- Logistic regression:\n",
    "    - 현재 벡터화에 TF-IDF, CountVectorizer사용 - 고차원 Sparse data가 형성되는데 이러한 고차원 데이터 학습을 효율적으로 할 수 있는 모델이어서 이러한 결과를 보인것으로 생각됨\n",
    "    - num_words의 경우 거의 비슷하지만 모든데이터를 사용한 학습에서 가장 높은 점수를 확인함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124330b-3cdc-47b1-9a14-ecd6b5313ce9",
   "metadata": {},
   "source": [
    "### 2) F1-Score 분석\n",
    "- F1 score는 정밀도(Precision)과 재현율(Recall)의 조화평균으로\n",
    "- 분류 클래스 간 데이터 불균형이 심각할 때 사용\n",
    "- 높을 수록 좋은 모델\n",
    "\n",
    "- Logistic regression\n",
    "    - Vocabulary Size: 3000 - Logistic Regression: 0.8008\n",
    "    - Vocabulary Size: 5000 - Logistic Regression: 0.7999\n",
    "    - Vocabulary Size: 10000 - Logistic Regression: 0.8023\n",
    "    - Vocabulary Size: None - Logistic Regression: 0.8055\n",
    "\n",
    "- Logistic regression:\n",
    "    - 각 클래스에 대한 확률 예측하는 모델, 불균형이 큰 데이터 학습에도 예측 성능이 뛰어남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373a7e5-c0e5-40a9-8765-1a94b93f20ab",
   "metadata": {},
   "source": [
    "### 3) Vocabulary Size 별 모델 성능\n",
    "\n",
    "- Logistic Regression: 모든 size에서 안정적으로 학습능력이 확인됨 - Accuracy 및 F1 score 기준으로\n",
    "- Voting Classifier: Logistic Regression 과 유사하지만 각 모델의 성능의 차이에 따라 약간의 차이는 있어보임\n",
    "- ComplementNB & Gradient Boosting: 모든 size에서 유사한 성능\n",
    "- MultinomialNB & Decision Tree: size가 클수록 성능이 떨어짐을 확인, 고차원 데이터에 약한 모델로 여겨짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47607810-12e9-4e2e-b9d0-50afec7414dc",
   "metadata": {},
   "source": [
    "### 회고\n",
    "- 다른 어떤 모델보다 Logistic Regression이 계속해서 안정적으로 점수가 확인되는 것이 인상적이었습니다.\\\n",
    "- 추가적으로 Logistic Regression과 Voting Classifier 하이퍼파라미터 조정으로 조금 더 성능을 높이고도 싶고 딥러닝과도 비교해 보고 싶었는데 생각보다 학습에 시간이 많이 소요되어 아쉬움이 남습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d8081-eed8-4b77-a267-b39a9657e4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
